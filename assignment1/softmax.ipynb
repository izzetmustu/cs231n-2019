{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "pdf-title"
    ]
   },
   "source": [
    "# Softmax exercise\n",
    "\n",
    "*Complete and hand in this completed worksheet (including its outputs and any supporting code outside of the worksheet) with your assignment submission. For more details see the [assignments page](http://vision.stanford.edu/teaching/cs231n/assignments.html) on the course website.*\n",
    "\n",
    "This exercise is analogous to the SVM exercise. You will:\n",
    "\n",
    "- implement a fully-vectorized **loss function** for the Softmax classifier\n",
    "- implement the fully-vectorized expression for its **analytic gradient**\n",
    "- **check your implementation** with numerical gradient\n",
    "- use a validation set to **tune the learning rate and regularization** strength\n",
    "- **optimize** the loss function with **SGD**\n",
    "- **visualize** the final learned weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": [
     "pdf-ignore"
    ]
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from cs231n.data_utils import load_CIFAR10\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading extenrnal modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [
     "pdf-ignore"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (49000, 3073)\n",
      "Train labels shape:  (49000,)\n",
      "Validation data shape:  (1000, 3073)\n",
      "Validation labels shape:  (1000,)\n",
      "Test data shape:  (1000, 3073)\n",
      "Test labels shape:  (1000,)\n",
      "dev data shape:  (500, 3073)\n",
      "dev labels shape:  (500,)\n"
     ]
    }
   ],
   "source": [
    "def get_CIFAR10_data(num_training=49000, num_validation=1000, num_test=1000, num_dev=500):\n",
    "    \"\"\"\n",
    "    Load the CIFAR-10 dataset from disk and perform preprocessing to prepare\n",
    "    it for the linear classifier. These are the same steps as we used for the\n",
    "    SVM, but condensed to a single function.  \n",
    "    \"\"\"\n",
    "    # Load the raw CIFAR-10 data\n",
    "    cifar10_dir = 'cs231n/datasets/cifar-10-batches-py'\n",
    "    \n",
    "    # Cleaning up variables to prevent loading data multiple times (which may cause memory issue)\n",
    "    try:\n",
    "       del X_train, y_train\n",
    "       del X_test, y_test\n",
    "       print('Clear previously loaded data.')\n",
    "    except:\n",
    "       pass\n",
    "\n",
    "    X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
    "    \n",
    "    # subsample the data\n",
    "    mask = list(range(num_training, num_training + num_validation))\n",
    "    X_val = X_train[mask]\n",
    "    y_val = y_train[mask]\n",
    "    mask = list(range(num_training))\n",
    "    X_train = X_train[mask]\n",
    "    y_train = y_train[mask]\n",
    "    mask = list(range(num_test))\n",
    "    X_test = X_test[mask]\n",
    "    y_test = y_test[mask]\n",
    "    mask = np.random.choice(num_training, num_dev, replace=False)\n",
    "    X_dev = X_train[mask]\n",
    "    y_dev = y_train[mask]\n",
    "    \n",
    "    # Preprocessing: reshape the image data into rows\n",
    "    X_train = np.reshape(X_train, (X_train.shape[0], -1))\n",
    "    X_val = np.reshape(X_val, (X_val.shape[0], -1))\n",
    "    X_test = np.reshape(X_test, (X_test.shape[0], -1))\n",
    "    X_dev = np.reshape(X_dev, (X_dev.shape[0], -1))\n",
    "    \n",
    "    # Normalize the data: subtract the mean image\n",
    "    mean_image = np.mean(X_train, axis = 0)\n",
    "    X_train -= mean_image\n",
    "    X_val -= mean_image\n",
    "    X_test -= mean_image\n",
    "    X_dev -= mean_image\n",
    "    \n",
    "    # add bias dimension and transform into columns\n",
    "    X_train = np.hstack([X_train, np.ones((X_train.shape[0], 1))])\n",
    "    X_val = np.hstack([X_val, np.ones((X_val.shape[0], 1))])\n",
    "    X_test = np.hstack([X_test, np.ones((X_test.shape[0], 1))])\n",
    "    X_dev = np.hstack([X_dev, np.ones((X_dev.shape[0], 1))])\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test, X_dev, y_dev\n",
    "\n",
    "\n",
    "# Invoke the above function to get our data.\n",
    "X_train, y_train, X_val, y_val, X_test, y_test, X_dev, y_dev = get_CIFAR10_data()\n",
    "print('Train data shape: ', X_train.shape)\n",
    "print('Train labels shape: ', y_train.shape)\n",
    "print('Validation data shape: ', X_val.shape)\n",
    "print('Validation labels shape: ', y_val.shape)\n",
    "print('Test data shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)\n",
    "print('dev data shape: ', X_dev.shape)\n",
    "print('dev labels shape: ', y_dev.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax Classifier\n",
    "\n",
    "Your code for this section will all be written inside **cs231n/classifiers/softmax.py**. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.357466\n",
      "sanity check: 2.302585\n"
     ]
    }
   ],
   "source": [
    "# First implement the naive softmax loss function with nested loops.\n",
    "# Open the file cs231n/classifiers/softmax.py and implement the\n",
    "# softmax_loss_naive function.\n",
    "\n",
    "from cs231n.classifiers.softmax import softmax_loss_naive\n",
    "import time\n",
    "\n",
    "# Generate a random softmax weight matrix and use it to compute the loss.\n",
    "W = np.random.randn(3073, 10) * 0.0001\n",
    "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 0.0)\n",
    "\n",
    "# As a rough sanity check, our loss should be something close to -log(0.1).\n",
    "print('loss: %f' % loss)\n",
    "print('sanity check: %f' % (-np.log(0.1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "pdf-inline"
    ]
   },
   "source": [
    "**Inline Question 1**\n",
    "\n",
    "Why do we expect our loss to be close to -log(0.1)? Explain briefly.**\n",
    "\n",
    "$\\color{blue}{\\textit Your Answer:}$ *At first, weights are so small and close to each other. So, predictions are very close to each other. Softmax gives us probabilities of each class inside -log() and since there are 10 classes, probability of each class at first is close to 0.1.* \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numerical: -3.642988 analytic: -3.642988, relative error: 1.563472e-08\n",
      "numerical: -0.712515 analytic: -0.712515, relative error: 6.472781e-09\n",
      "numerical: -1.624444 analytic: -1.624444, relative error: 1.915092e-08\n",
      "numerical: 3.289764 analytic: 3.289764, relative error: 2.161841e-08\n",
      "numerical: 0.193649 analytic: 0.193648, relative error: 1.164995e-07\n",
      "numerical: -1.142467 analytic: -1.142467, relative error: 4.447735e-08\n",
      "numerical: 0.660228 analytic: 0.660228, relative error: 2.494809e-08\n",
      "numerical: 0.520665 analytic: 0.520664, relative error: 1.382163e-07\n",
      "numerical: 0.280971 analytic: 0.280971, relative error: 2.148651e-07\n",
      "numerical: 0.465870 analytic: 0.465870, relative error: 1.177216e-08\n",
      "numerical: 3.051758 analytic: 4.220376, relative error: 1.606981e-01\n",
      "numerical: 3.051758 analytic: 2.432476, relative error: 1.129203e-01\n",
      "numerical: 0.000000 analytic: 0.538452, relative error: 1.000000e+00\n",
      "numerical: 0.000000 analytic: 0.754628, relative error: 1.000000e+00\n",
      "numerical: 0.000000 analytic: 1.098253, relative error: 1.000000e+00\n",
      "numerical: -3.051758 analytic: -2.072434, relative error: 1.911178e-01\n",
      "numerical: -3.051758 analytic: -2.980213, relative error: 1.186095e-02\n",
      "numerical: 0.000000 analytic: 0.741494, relative error: 1.000000e+00\n",
      "numerical: -3.051758 analytic: -4.208454, relative error: 1.593199e-01\n",
      "numerical: 3.051758 analytic: 1.685898, relative error: 2.882986e-01\n"
     ]
    }
   ],
   "source": [
    "# Complete the implementation of softmax_loss_naive and implement a (naive)\n",
    "# version of the gradient that uses nested loops.\n",
    "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 0.0)\n",
    "\n",
    "# As we did for the SVM, use numeric gradient checking as a debugging tool.\n",
    "# The numeric gradient should be close to the analytic gradient.\n",
    "from cs231n.gradient_check import grad_check_sparse\n",
    "f = lambda w: softmax_loss_naive(w, X_dev, y_dev, 0.0)[0]\n",
    "grad_numerical = grad_check_sparse(f, W, grad, 10)\n",
    "\n",
    "# similar to SVM case, do another gradient check with regularization\n",
    "loss, grad = softmax_loss_naive(W, X_dev, y_dev, 5e1)\n",
    "f = lambda w: softmax_loss_naive(w, X_dev, y_dev, 5e1)[0]\n",
    "grad_numerical = grad_check_sparse(f, W, grad, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "naive loss: 3.147818e+04 computed in 0.075069s\n",
      "vectorized loss: 3.147818e+04 computed in 0.005006s\n",
      "Loss difference: 0.000000\n",
      "Gradient difference: 0.000000\n"
     ]
    }
   ],
   "source": [
    "# Now that we have a naive implementation of the softmax loss function and its gradient,\n",
    "# implement a vectorized version in softmax_loss_vectorized.\n",
    "# The two versions should compute the same results, but the vectorized version should be\n",
    "# much faster.\n",
    "tic = time.time()\n",
    "loss_naive, grad_naive = softmax_loss_naive(W, X_dev, y_dev, 0.000005)\n",
    "toc = time.time()\n",
    "print('naive loss: %e computed in %fs' % (loss_naive, toc - tic))\n",
    "\n",
    "from cs231n.classifiers.softmax import softmax_loss_vectorized\n",
    "tic = time.time()\n",
    "loss_vectorized, grad_vectorized = softmax_loss_vectorized(W, X_dev, y_dev, 0.000005)\n",
    "toc = time.time()\n",
    "print('vectorized loss: %e computed in %fs' % (loss_vectorized, toc - tic))\n",
    "\n",
    "# As we did for the SVM, we use the Frobenius norm to compare the two versions\n",
    "# of the gradient.\n",
    "grad_difference = np.linalg.norm(grad_naive - grad_vectorized, ord='fro')\n",
    "print('Loss difference: %f' % np.abs(loss_naive - loss_vectorized))\n",
    "print('Gradient difference: %f' % grad_difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "code"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr 1.000000e-07 reg 2.500000e+04 train accuracy: 0.330878 val accuracy: 0.334000\n",
      "lr 1.000000e-07 reg 2.777778e+04 train accuracy: 0.331776 val accuracy: 0.347000\n",
      "lr 1.000000e-07 reg 3.055556e+04 train accuracy: 0.321592 val accuracy: 0.340000\n",
      "lr 1.000000e-07 reg 3.333333e+04 train accuracy: 0.320918 val accuracy: 0.334000\n",
      "lr 1.000000e-07 reg 3.611111e+04 train accuracy: 0.321388 val accuracy: 0.327000\n",
      "lr 1.000000e-07 reg 3.888889e+04 train accuracy: 0.314469 val accuracy: 0.335000\n",
      "lr 1.000000e-07 reg 4.166667e+04 train accuracy: 0.317204 val accuracy: 0.330000\n",
      "lr 1.000000e-07 reg 4.444444e+04 train accuracy: 0.310143 val accuracy: 0.332000\n",
      "lr 1.000000e-07 reg 4.722222e+04 train accuracy: 0.298408 val accuracy: 0.320000\n",
      "lr 1.000000e-07 reg 5.000000e+04 train accuracy: 0.314776 val accuracy: 0.333000\n",
      "lr 1.210526e-07 reg 2.500000e+04 train accuracy: 0.324388 val accuracy: 0.344000\n",
      "lr 1.210526e-07 reg 2.777778e+04 train accuracy: 0.320959 val accuracy: 0.333000\n",
      "lr 1.210526e-07 reg 3.055556e+04 train accuracy: 0.313959 val accuracy: 0.327000\n",
      "lr 1.210526e-07 reg 3.333333e+04 train accuracy: 0.322837 val accuracy: 0.334000\n",
      "lr 1.210526e-07 reg 3.611111e+04 train accuracy: 0.315041 val accuracy: 0.335000\n",
      "lr 1.210526e-07 reg 3.888889e+04 train accuracy: 0.314939 val accuracy: 0.330000\n",
      "lr 1.210526e-07 reg 4.166667e+04 train accuracy: 0.303694 val accuracy: 0.318000\n",
      "lr 1.210526e-07 reg 4.444444e+04 train accuracy: 0.306469 val accuracy: 0.329000\n",
      "lr 1.210526e-07 reg 4.722222e+04 train accuracy: 0.304224 val accuracy: 0.326000\n",
      "lr 1.210526e-07 reg 5.000000e+04 train accuracy: 0.310959 val accuracy: 0.326000\n",
      "lr 1.421053e-07 reg 2.500000e+04 train accuracy: 0.331551 val accuracy: 0.341000\n",
      "lr 1.421053e-07 reg 2.777778e+04 train accuracy: 0.322102 val accuracy: 0.340000\n",
      "lr 1.421053e-07 reg 3.055556e+04 train accuracy: 0.317306 val accuracy: 0.331000\n",
      "lr 1.421053e-07 reg 3.333333e+04 train accuracy: 0.321857 val accuracy: 0.345000\n",
      "lr 1.421053e-07 reg 3.611111e+04 train accuracy: 0.317918 val accuracy: 0.338000\n",
      "lr 1.421053e-07 reg 3.888889e+04 train accuracy: 0.319980 val accuracy: 0.324000\n",
      "lr 1.421053e-07 reg 4.166667e+04 train accuracy: 0.310592 val accuracy: 0.325000\n",
      "lr 1.421053e-07 reg 4.444444e+04 train accuracy: 0.307306 val accuracy: 0.326000\n",
      "lr 1.421053e-07 reg 4.722222e+04 train accuracy: 0.300694 val accuracy: 0.324000\n",
      "lr 1.421053e-07 reg 5.000000e+04 train accuracy: 0.314122 val accuracy: 0.329000\n",
      "lr 1.631579e-07 reg 2.500000e+04 train accuracy: 0.332592 val accuracy: 0.351000\n",
      "lr 1.631579e-07 reg 2.777778e+04 train accuracy: 0.322776 val accuracy: 0.341000\n",
      "lr 1.631579e-07 reg 3.055556e+04 train accuracy: 0.324776 val accuracy: 0.339000\n",
      "lr 1.631579e-07 reg 3.333333e+04 train accuracy: 0.325347 val accuracy: 0.341000\n",
      "lr 1.631579e-07 reg 3.611111e+04 train accuracy: 0.316408 val accuracy: 0.331000\n",
      "lr 1.631579e-07 reg 3.888889e+04 train accuracy: 0.325633 val accuracy: 0.339000\n",
      "lr 1.631579e-07 reg 4.166667e+04 train accuracy: 0.314020 val accuracy: 0.331000\n",
      "lr 1.631579e-07 reg 4.444444e+04 train accuracy: 0.303306 val accuracy: 0.320000\n",
      "lr 1.631579e-07 reg 4.722222e+04 train accuracy: 0.307653 val accuracy: 0.313000\n",
      "lr 1.631579e-07 reg 5.000000e+04 train accuracy: 0.314612 val accuracy: 0.323000\n",
      "lr 1.842105e-07 reg 2.500000e+04 train accuracy: 0.325490 val accuracy: 0.337000\n",
      "lr 1.842105e-07 reg 2.777778e+04 train accuracy: 0.329000 val accuracy: 0.341000\n",
      "lr 1.842105e-07 reg 3.055556e+04 train accuracy: 0.329224 val accuracy: 0.337000\n",
      "lr 1.842105e-07 reg 3.333333e+04 train accuracy: 0.315061 val accuracy: 0.333000\n",
      "lr 1.842105e-07 reg 3.611111e+04 train accuracy: 0.314776 val accuracy: 0.336000\n",
      "lr 1.842105e-07 reg 3.888889e+04 train accuracy: 0.304694 val accuracy: 0.324000\n",
      "lr 1.842105e-07 reg 4.166667e+04 train accuracy: 0.312286 val accuracy: 0.322000\n",
      "lr 1.842105e-07 reg 4.444444e+04 train accuracy: 0.306327 val accuracy: 0.320000\n",
      "lr 1.842105e-07 reg 4.722222e+04 train accuracy: 0.303143 val accuracy: 0.314000\n",
      "lr 1.842105e-07 reg 5.000000e+04 train accuracy: 0.310265 val accuracy: 0.334000\n",
      "lr 2.052632e-07 reg 2.500000e+04 train accuracy: 0.331449 val accuracy: 0.342000\n",
      "lr 2.052632e-07 reg 2.777778e+04 train accuracy: 0.325286 val accuracy: 0.347000\n",
      "lr 2.052632e-07 reg 3.055556e+04 train accuracy: 0.325367 val accuracy: 0.338000\n",
      "lr 2.052632e-07 reg 3.333333e+04 train accuracy: 0.324020 val accuracy: 0.336000\n",
      "lr 2.052632e-07 reg 3.611111e+04 train accuracy: 0.312327 val accuracy: 0.322000\n",
      "lr 2.052632e-07 reg 3.888889e+04 train accuracy: 0.309776 val accuracy: 0.329000\n",
      "lr 2.052632e-07 reg 4.166667e+04 train accuracy: 0.316571 val accuracy: 0.333000\n",
      "lr 2.052632e-07 reg 4.444444e+04 train accuracy: 0.304469 val accuracy: 0.311000\n",
      "lr 2.052632e-07 reg 4.722222e+04 train accuracy: 0.310490 val accuracy: 0.325000\n",
      "lr 2.052632e-07 reg 5.000000e+04 train accuracy: 0.308531 val accuracy: 0.322000\n",
      "lr 2.263158e-07 reg 2.500000e+04 train accuracy: 0.327939 val accuracy: 0.342000\n",
      "lr 2.263158e-07 reg 2.777778e+04 train accuracy: 0.321878 val accuracy: 0.335000\n",
      "lr 2.263158e-07 reg 3.055556e+04 train accuracy: 0.328612 val accuracy: 0.347000\n",
      "lr 2.263158e-07 reg 3.333333e+04 train accuracy: 0.323306 val accuracy: 0.330000\n",
      "lr 2.263158e-07 reg 3.611111e+04 train accuracy: 0.317510 val accuracy: 0.329000\n",
      "lr 2.263158e-07 reg 3.888889e+04 train accuracy: 0.305102 val accuracy: 0.321000\n",
      "lr 2.263158e-07 reg 4.166667e+04 train accuracy: 0.314653 val accuracy: 0.328000\n",
      "lr 2.263158e-07 reg 4.444444e+04 train accuracy: 0.302306 val accuracy: 0.318000\n",
      "lr 2.263158e-07 reg 4.722222e+04 train accuracy: 0.314061 val accuracy: 0.331000\n",
      "lr 2.263158e-07 reg 5.000000e+04 train accuracy: 0.289143 val accuracy: 0.308000\n",
      "lr 2.473684e-07 reg 2.500000e+04 train accuracy: 0.326612 val accuracy: 0.341000\n",
      "lr 2.473684e-07 reg 2.777778e+04 train accuracy: 0.326286 val accuracy: 0.343000\n",
      "lr 2.473684e-07 reg 3.055556e+04 train accuracy: 0.328449 val accuracy: 0.340000\n",
      "lr 2.473684e-07 reg 3.333333e+04 train accuracy: 0.323551 val accuracy: 0.338000\n",
      "lr 2.473684e-07 reg 3.611111e+04 train accuracy: 0.324816 val accuracy: 0.341000\n",
      "lr 2.473684e-07 reg 3.888889e+04 train accuracy: 0.308837 val accuracy: 0.326000\n",
      "lr 2.473684e-07 reg 4.166667e+04 train accuracy: 0.308959 val accuracy: 0.322000\n",
      "lr 2.473684e-07 reg 4.444444e+04 train accuracy: 0.304469 val accuracy: 0.323000\n",
      "lr 2.473684e-07 reg 4.722222e+04 train accuracy: 0.306837 val accuracy: 0.315000\n",
      "lr 2.473684e-07 reg 5.000000e+04 train accuracy: 0.305041 val accuracy: 0.316000\n",
      "lr 2.684211e-07 reg 2.500000e+04 train accuracy: 0.331020 val accuracy: 0.343000\n",
      "lr 2.684211e-07 reg 2.777778e+04 train accuracy: 0.316041 val accuracy: 0.335000\n",
      "lr 2.684211e-07 reg 3.055556e+04 train accuracy: 0.330816 val accuracy: 0.340000\n",
      "lr 2.684211e-07 reg 3.333333e+04 train accuracy: 0.307755 val accuracy: 0.327000\n",
      "lr 2.684211e-07 reg 3.611111e+04 train accuracy: 0.309327 val accuracy: 0.324000\n",
      "lr 2.684211e-07 reg 3.888889e+04 train accuracy: 0.313612 val accuracy: 0.321000\n",
      "lr 2.684211e-07 reg 4.166667e+04 train accuracy: 0.300000 val accuracy: 0.323000\n",
      "lr 2.684211e-07 reg 4.444444e+04 train accuracy: 0.294224 val accuracy: 0.306000\n",
      "lr 2.684211e-07 reg 4.722222e+04 train accuracy: 0.314041 val accuracy: 0.319000\n",
      "lr 2.684211e-07 reg 5.000000e+04 train accuracy: 0.302102 val accuracy: 0.318000\n",
      "lr 2.894737e-07 reg 2.500000e+04 train accuracy: 0.328816 val accuracy: 0.355000\n",
      "lr 2.894737e-07 reg 2.777778e+04 train accuracy: 0.325633 val accuracy: 0.338000\n",
      "lr 2.894737e-07 reg 3.055556e+04 train accuracy: 0.322122 val accuracy: 0.334000\n",
      "lr 2.894737e-07 reg 3.333333e+04 train accuracy: 0.322653 val accuracy: 0.327000\n",
      "lr 2.894737e-07 reg 3.611111e+04 train accuracy: 0.322918 val accuracy: 0.329000\n",
      "lr 2.894737e-07 reg 3.888889e+04 train accuracy: 0.313796 val accuracy: 0.323000\n",
      "lr 2.894737e-07 reg 4.166667e+04 train accuracy: 0.316755 val accuracy: 0.334000\n",
      "lr 2.894737e-07 reg 4.444444e+04 train accuracy: 0.305857 val accuracy: 0.320000\n",
      "lr 2.894737e-07 reg 4.722222e+04 train accuracy: 0.315388 val accuracy: 0.324000\n",
      "lr 2.894737e-07 reg 5.000000e+04 train accuracy: 0.307714 val accuracy: 0.316000\n",
      "lr 3.105263e-07 reg 2.500000e+04 train accuracy: 0.314755 val accuracy: 0.336000\n",
      "lr 3.105263e-07 reg 2.777778e+04 train accuracy: 0.315286 val accuracy: 0.330000\n",
      "lr 3.105263e-07 reg 3.055556e+04 train accuracy: 0.328388 val accuracy: 0.344000\n",
      "lr 3.105263e-07 reg 3.333333e+04 train accuracy: 0.320184 val accuracy: 0.337000\n",
      "lr 3.105263e-07 reg 3.611111e+04 train accuracy: 0.304980 val accuracy: 0.328000\n",
      "lr 3.105263e-07 reg 3.888889e+04 train accuracy: 0.320327 val accuracy: 0.327000\n",
      "lr 3.105263e-07 reg 4.166667e+04 train accuracy: 0.318837 val accuracy: 0.329000\n",
      "lr 3.105263e-07 reg 4.444444e+04 train accuracy: 0.298122 val accuracy: 0.320000\n",
      "lr 3.105263e-07 reg 4.722222e+04 train accuracy: 0.307816 val accuracy: 0.320000\n",
      "lr 3.105263e-07 reg 5.000000e+04 train accuracy: 0.301878 val accuracy: 0.315000\n",
      "lr 3.315789e-07 reg 2.500000e+04 train accuracy: 0.328204 val accuracy: 0.342000\n",
      "lr 3.315789e-07 reg 2.777778e+04 train accuracy: 0.329224 val accuracy: 0.338000\n",
      "lr 3.315789e-07 reg 3.055556e+04 train accuracy: 0.320571 val accuracy: 0.335000\n",
      "lr 3.315789e-07 reg 3.333333e+04 train accuracy: 0.313388 val accuracy: 0.334000\n",
      "lr 3.315789e-07 reg 3.611111e+04 train accuracy: 0.313673 val accuracy: 0.330000\n",
      "lr 3.315789e-07 reg 3.888889e+04 train accuracy: 0.302816 val accuracy: 0.313000\n",
      "lr 3.315789e-07 reg 4.166667e+04 train accuracy: 0.313490 val accuracy: 0.331000\n",
      "lr 3.315789e-07 reg 4.444444e+04 train accuracy: 0.304878 val accuracy: 0.323000\n",
      "lr 3.315789e-07 reg 4.722222e+04 train accuracy: 0.297429 val accuracy: 0.304000\n",
      "lr 3.315789e-07 reg 5.000000e+04 train accuracy: 0.289959 val accuracy: 0.305000\n",
      "lr 3.526316e-07 reg 2.500000e+04 train accuracy: 0.333490 val accuracy: 0.350000\n",
      "lr 3.526316e-07 reg 2.777778e+04 train accuracy: 0.321551 val accuracy: 0.329000\n",
      "lr 3.526316e-07 reg 3.055556e+04 train accuracy: 0.313714 val accuracy: 0.333000\n",
      "lr 3.526316e-07 reg 3.333333e+04 train accuracy: 0.308347 val accuracy: 0.323000\n",
      "lr 3.526316e-07 reg 3.611111e+04 train accuracy: 0.318878 val accuracy: 0.332000\n",
      "lr 3.526316e-07 reg 3.888889e+04 train accuracy: 0.307020 val accuracy: 0.326000\n",
      "lr 3.526316e-07 reg 4.166667e+04 train accuracy: 0.300735 val accuracy: 0.316000\n",
      "lr 3.526316e-07 reg 4.444444e+04 train accuracy: 0.299776 val accuracy: 0.315000\n",
      "lr 3.526316e-07 reg 4.722222e+04 train accuracy: 0.301041 val accuracy: 0.317000\n",
      "lr 3.526316e-07 reg 5.000000e+04 train accuracy: 0.307490 val accuracy: 0.327000\n",
      "lr 3.736842e-07 reg 2.500000e+04 train accuracy: 0.326816 val accuracy: 0.344000\n",
      "lr 3.736842e-07 reg 2.777778e+04 train accuracy: 0.330592 val accuracy: 0.345000\n",
      "lr 3.736842e-07 reg 3.055556e+04 train accuracy: 0.319306 val accuracy: 0.343000\n",
      "lr 3.736842e-07 reg 3.333333e+04 train accuracy: 0.311878 val accuracy: 0.325000\n",
      "lr 3.736842e-07 reg 3.611111e+04 train accuracy: 0.311429 val accuracy: 0.332000\n",
      "lr 3.736842e-07 reg 3.888889e+04 train accuracy: 0.311816 val accuracy: 0.326000\n",
      "lr 3.736842e-07 reg 4.166667e+04 train accuracy: 0.313327 val accuracy: 0.327000\n",
      "lr 3.736842e-07 reg 4.444444e+04 train accuracy: 0.313061 val accuracy: 0.326000\n",
      "lr 3.736842e-07 reg 4.722222e+04 train accuracy: 0.311837 val accuracy: 0.319000\n",
      "lr 3.736842e-07 reg 5.000000e+04 train accuracy: 0.314204 val accuracy: 0.328000\n",
      "lr 3.947368e-07 reg 2.500000e+04 train accuracy: 0.331755 val accuracy: 0.344000\n",
      "lr 3.947368e-07 reg 2.777778e+04 train accuracy: 0.315714 val accuracy: 0.329000\n",
      "lr 3.947368e-07 reg 3.055556e+04 train accuracy: 0.309898 val accuracy: 0.328000\n",
      "lr 3.947368e-07 reg 3.333333e+04 train accuracy: 0.318061 val accuracy: 0.334000\n",
      "lr 3.947368e-07 reg 3.611111e+04 train accuracy: 0.312571 val accuracy: 0.332000\n",
      "lr 3.947368e-07 reg 3.888889e+04 train accuracy: 0.307510 val accuracy: 0.323000\n",
      "lr 3.947368e-07 reg 4.166667e+04 train accuracy: 0.304776 val accuracy: 0.318000\n",
      "lr 3.947368e-07 reg 4.444444e+04 train accuracy: 0.310612 val accuracy: 0.333000\n",
      "lr 3.947368e-07 reg 4.722222e+04 train accuracy: 0.308633 val accuracy: 0.323000\n",
      "lr 3.947368e-07 reg 5.000000e+04 train accuracy: 0.306286 val accuracy: 0.322000\n",
      "lr 4.157895e-07 reg 2.500000e+04 train accuracy: 0.322408 val accuracy: 0.333000\n",
      "lr 4.157895e-07 reg 2.777778e+04 train accuracy: 0.315959 val accuracy: 0.340000\n",
      "lr 4.157895e-07 reg 3.055556e+04 train accuracy: 0.324898 val accuracy: 0.338000\n",
      "lr 4.157895e-07 reg 3.333333e+04 train accuracy: 0.311490 val accuracy: 0.333000\n",
      "lr 4.157895e-07 reg 3.611111e+04 train accuracy: 0.322020 val accuracy: 0.326000\n",
      "lr 4.157895e-07 reg 3.888889e+04 train accuracy: 0.311224 val accuracy: 0.327000\n",
      "lr 4.157895e-07 reg 4.166667e+04 train accuracy: 0.313449 val accuracy: 0.329000\n",
      "lr 4.157895e-07 reg 4.444444e+04 train accuracy: 0.295694 val accuracy: 0.317000\n",
      "lr 4.157895e-07 reg 4.722222e+04 train accuracy: 0.312245 val accuracy: 0.327000\n",
      "lr 4.157895e-07 reg 5.000000e+04 train accuracy: 0.307469 val accuracy: 0.327000\n",
      "lr 4.368421e-07 reg 2.500000e+04 train accuracy: 0.333245 val accuracy: 0.350000\n",
      "lr 4.368421e-07 reg 2.777778e+04 train accuracy: 0.319735 val accuracy: 0.331000\n",
      "lr 4.368421e-07 reg 3.055556e+04 train accuracy: 0.322265 val accuracy: 0.340000\n",
      "lr 4.368421e-07 reg 3.333333e+04 train accuracy: 0.315571 val accuracy: 0.324000\n",
      "lr 4.368421e-07 reg 3.611111e+04 train accuracy: 0.317327 val accuracy: 0.328000\n",
      "lr 4.368421e-07 reg 3.888889e+04 train accuracy: 0.320510 val accuracy: 0.335000\n",
      "lr 4.368421e-07 reg 4.166667e+04 train accuracy: 0.302878 val accuracy: 0.325000\n",
      "lr 4.368421e-07 reg 4.444444e+04 train accuracy: 0.300184 val accuracy: 0.315000\n",
      "lr 4.368421e-07 reg 4.722222e+04 train accuracy: 0.304571 val accuracy: 0.327000\n",
      "lr 4.368421e-07 reg 5.000000e+04 train accuracy: 0.300571 val accuracy: 0.315000\n",
      "lr 4.578947e-07 reg 2.500000e+04 train accuracy: 0.322347 val accuracy: 0.337000\n",
      "lr 4.578947e-07 reg 2.777778e+04 train accuracy: 0.324816 val accuracy: 0.344000\n",
      "lr 4.578947e-07 reg 3.055556e+04 train accuracy: 0.319959 val accuracy: 0.339000\n",
      "lr 4.578947e-07 reg 3.333333e+04 train accuracy: 0.322245 val accuracy: 0.332000\n",
      "lr 4.578947e-07 reg 3.611111e+04 train accuracy: 0.310857 val accuracy: 0.320000\n",
      "lr 4.578947e-07 reg 3.888889e+04 train accuracy: 0.313531 val accuracy: 0.320000\n",
      "lr 4.578947e-07 reg 4.166667e+04 train accuracy: 0.305571 val accuracy: 0.327000\n",
      "lr 4.578947e-07 reg 4.444444e+04 train accuracy: 0.299490 val accuracy: 0.318000\n",
      "lr 4.578947e-07 reg 4.722222e+04 train accuracy: 0.313653 val accuracy: 0.326000\n",
      "lr 4.578947e-07 reg 5.000000e+04 train accuracy: 0.316224 val accuracy: 0.321000\n",
      "lr 4.789474e-07 reg 2.500000e+04 train accuracy: 0.314367 val accuracy: 0.330000\n",
      "lr 4.789474e-07 reg 2.777778e+04 train accuracy: 0.319306 val accuracy: 0.324000\n",
      "lr 4.789474e-07 reg 3.055556e+04 train accuracy: 0.325388 val accuracy: 0.341000\n",
      "lr 4.789474e-07 reg 3.333333e+04 train accuracy: 0.314837 val accuracy: 0.327000\n",
      "lr 4.789474e-07 reg 3.611111e+04 train accuracy: 0.323714 val accuracy: 0.343000\n",
      "lr 4.789474e-07 reg 3.888889e+04 train accuracy: 0.305122 val accuracy: 0.318000\n",
      "lr 4.789474e-07 reg 4.166667e+04 train accuracy: 0.297816 val accuracy: 0.305000\n",
      "lr 4.789474e-07 reg 4.444444e+04 train accuracy: 0.311980 val accuracy: 0.334000\n",
      "lr 4.789474e-07 reg 4.722222e+04 train accuracy: 0.319776 val accuracy: 0.327000\n",
      "lr 4.789474e-07 reg 5.000000e+04 train accuracy: 0.301204 val accuracy: 0.320000\n",
      "lr 5.000000e-07 reg 2.500000e+04 train accuracy: 0.325612 val accuracy: 0.326000\n",
      "lr 5.000000e-07 reg 2.777778e+04 train accuracy: 0.320653 val accuracy: 0.327000\n",
      "lr 5.000000e-07 reg 3.055556e+04 train accuracy: 0.314551 val accuracy: 0.331000\n",
      "lr 5.000000e-07 reg 3.333333e+04 train accuracy: 0.321714 val accuracy: 0.316000\n",
      "lr 5.000000e-07 reg 3.611111e+04 train accuracy: 0.317816 val accuracy: 0.336000\n",
      "lr 5.000000e-07 reg 3.888889e+04 train accuracy: 0.306837 val accuracy: 0.326000\n",
      "lr 5.000000e-07 reg 4.166667e+04 train accuracy: 0.315000 val accuracy: 0.325000\n",
      "lr 5.000000e-07 reg 4.444444e+04 train accuracy: 0.305265 val accuracy: 0.317000\n",
      "lr 5.000000e-07 reg 4.722222e+04 train accuracy: 0.310184 val accuracy: 0.328000\n",
      "lr 5.000000e-07 reg 5.000000e+04 train accuracy: 0.305102 val accuracy: 0.312000\n",
      "best validation accuracy achieved during cross-validation: 0.355000\n"
     ]
    }
   ],
   "source": [
    "# Use the validation set to tune hyperparameters (regularization strength and\n",
    "# learning rate). You should experiment with different ranges for the learning\n",
    "# rates and regularization strengths; if you are careful you should be able to\n",
    "# get a classification accuracy of over 0.35 on the validation set.\n",
    "from cs231n.classifiers import Softmax\n",
    "results = {}\n",
    "best_val = -1\n",
    "best_softmax = None\n",
    "learning_rates = [1e-7, 5e-7]\n",
    "regularization_strengths = [2.5e4, 5e4]\n",
    "\n",
    "################################################################################\n",
    "# TODO:                                                                        #\n",
    "# Use the validation set to set the learning rate and regularization strength. #\n",
    "# This should be identical to the validation that you did for the SVM; save    #\n",
    "# the best trained softmax classifer in best_softmax.                          #\n",
    "################################################################################\n",
    "# *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "learning_rates = np.linspace(learning_rates[0], learning_rates[1], 20)\n",
    "regularization_strengths = np.linspace(regularization_strengths[0], regularization_strengths[1], 10)\n",
    "\n",
    "for i in range(learning_rates.shape[0]):\n",
    "    for j in range(regularization_strengths.shape[0]):\n",
    "        # Create a SVM classifier object\n",
    "        trainer_object = Softmax()\n",
    "        \n",
    "        # Train \n",
    "        loss_list = trainer_object.train(X_train, y_train, learning_rates[i], regularization_strengths[j], num_iters=1500)\n",
    "        \n",
    "        # Prediction for training data\n",
    "        y_pred = trainer_object.predict(X_train)\n",
    "        # Accuracy for training data\n",
    "        y_pred_accuracy = np.mean(y_train == y_pred)\n",
    "\n",
    "        # Prediction for validation data\n",
    "        y_pred_val = trainer_object.predict(X_val)\n",
    "        # Accuracy for validation data\n",
    "        y_pred_val_accuracy = np.mean(y_val == y_pred_val)\n",
    "\n",
    "        # Store results\n",
    "        results[(learning_rates[i], regularization_strengths[j])] = (y_pred_accuracy, y_pred_val_accuracy)\n",
    "        # Compare validation score with best one store the best trainer object\n",
    "        if y_pred_val_accuracy > best_val:\n",
    "            best_val = y_pred_val_accuracy\n",
    "            best_softmax = trainer_object\n",
    "        trainer_object = None\n",
    "\n",
    "# *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    \n",
    "# Print out results.\n",
    "for lr, reg in sorted(results):\n",
    "    train_accuracy, val_accuracy = results[(lr, reg)]\n",
    "    print('lr %e reg %e train accuracy: %f val accuracy: %f' % (\n",
    "                lr, reg, train_accuracy, val_accuracy))\n",
    "    \n",
    "print('best validation accuracy achieved during cross-validation: %f' % best_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax on raw pixels final test set accuracy: 0.350000\n"
     ]
    }
   ],
   "source": [
    "# evaluate on test set\n",
    "# Evaluate the best softmax on test set\n",
    "y_test_pred = best_softmax.predict(X_test)\n",
    "test_accuracy = np.mean(y_test == y_test_pred)\n",
    "print('softmax on raw pixels final test set accuracy: %f' % (test_accuracy, ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "pdf-inline"
    ]
   },
   "source": [
    "**Inline Question 2** - *True or False*\n",
    "\n",
    "Suppose the overall training loss is defined as the sum of the per-datapoint loss over all training examples. It is possible to add a new datapoint to a training set that would leave the SVM loss unchanged, but this is not the case with the Softmax classifier loss.\n",
    "\n",
    "$\\color{blue}{\\textit Your Answer:}$ \n",
    "\n",
    "*True*\n",
    "\n",
    "\n",
    "$\\color{blue}{\\textit Your Explanation:}$\n",
    "\n",
    "*SVM loss is nonzero only a gap margin is not satisfied. If a gap margin is satisfied for a datapoint then SVM loss becomes zero. On the other hand, in order softmax loss to became zero, softmax function should return 1, which means exponential values of other class scores have to be 0. This situation only happens when false class scores(y=X@W) are negative infinitiy.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the learned weights for each class\n",
    "w = best_softmax.W[:-1,:] # strip out the bias\n",
    "w = w.reshape(32, 32, 3, 10)\n",
    "\n",
    "w_min, w_max = np.min(w), np.max(w)\n",
    "\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "for i in range(10):\n",
    "    plt.subplot(2, 5, i + 1)\n",
    "    \n",
    "    # Rescale the weights to be between 0 and 255\n",
    "    wimg = 255.0 * (w[:, :, :, i].squeeze() - w_min) / (w_max - w_min)\n",
    "    plt.imshow(wimg.astype('uint8'))\n",
    "    plt.axis('off')\n",
    "    plt.title(classes[i])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "00b5576e8b3626ecdb1d066e48490e95de53519858b875a471fa77ffbf2a8308"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('cs231n')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "00b5576e8b3626ecdb1d066e48490e95de53519858b875a471fa77ffbf2a8308"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
